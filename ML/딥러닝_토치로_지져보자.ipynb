{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python [default]",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    },
    "colab": {
      "name": "딥러닝... 토치로 지져보자.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/skdding3/Code-Practice/blob/main/ML/%EB%94%A5%EB%9F%AC%EB%8B%9D_%ED%86%A0%EC%B9%98%EB%A1%9C_%EC%A7%80%EC%A0%B8%EB%B3%B4%EC%9E%90.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JtJqFZ_UKWCT"
      },
      "source": [
        "# PyTorch\n",
        "\n",
        "딥러닝(Deep Learning)을 구현할 때 현재 가장 많이 사용하는 라이브러리는 텐서플로우(Tensorflow)이다. 하지만, 최근 급부상하고 있는 딥러닝 라이브러리가 있다, 그것은 바로 파이토치(Pytorch)이다. Pytorch에 대해서 자세히 살펴보자."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Ydr7ATsKWCT"
      },
      "source": [
        "참고 자료 [kaggle-MNIST](https://www.kaggle.com/vincentlefoulon/pytorch-mnist)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Yt-h1qKKWCU"
      },
      "source": [
        "from __future__ import print_function"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGipHOatKWCU",
        "outputId": "0d0877de-3d1b-4442-c863-3785142d79cd"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy\n",
        "import tensorflow"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/Users/teddylee/miniconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
            "  from ._conv import register_converters as _register_converters\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8eCaL6EtKWCV",
        "outputId": "a8cf1d72-3582-469a-ddf1-df9ddd1985bf"
      },
      "source": [
        "import sys\n",
        "sys.executable"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/Users/teddylee/miniconda3/bin/python'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OR2SEL9WKWCW"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHuQOd7KKWCW"
      },
      "source": [
        "# PyTorch Basic Functions and Usages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZcE8YXsHKWCX"
      },
      "source": [
        "## Basic"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YiVAf-eGKWCX",
        "outputId": "94dcd54b-cf06-4ee8-c51b-d0981eb9069f"
      },
      "source": [
        "# construct uninitialize tensor\n",
        "x = torch.empty(3, 5)\n",
        "x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0000e+00,  1.0842e-19, -2.0566e+10,  8.5920e+09,  7.0065e-45],\n",
              "        [ 0.0000e+00,  3.5285e-33,  4.5779e-41,  3.5285e-33,  4.5779e-41],\n",
              "        [ 3.5522e-33,  4.5559e-41,  3.5522e-33,  4.5779e-41,  3.5522e-33]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fexFK4D1KWCY",
        "outputId": "b006db8c-d1e9-458c-ff30-a4e102de4fb9"
      },
      "source": [
        "# check tensor size\n",
        "x.size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmAeg0WMKWCY",
        "outputId": "77ddced0-f531-441a-f18a-704a3e2bce29"
      },
      "source": [
        "# generate random tensors\n",
        "y = torch.randn(3, 5)\n",
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.4295,  0.9393,  1.2178,  0.6311, -1.8682],\n",
              "        [ 0.4992, -0.6476,  1.1434, -0.6581,  0.0639],\n",
              "        [-0.2660, -0.1764, -0.4660,  1.2395, -0.0004]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vYsumhnKWCY",
        "outputId": "70ed92a6-f392-4eb1-856b-cf13fea8140a"
      },
      "source": [
        "# zeros and ones\n",
        "print(torch.zeros(3, 5))\n",
        "print(torch.ones(3, 5))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.]])\n",
            "tensor([[1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAp-MnV5KWCZ"
      },
      "source": [
        "## Broadcast Calculation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLS4hKoEKWCZ",
        "outputId": "18ee333a-c65c-4c8d-b7f1-e3c593af8e07"
      },
      "source": [
        "# add\n",
        "torch.add(x, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.4295e+00,  9.3930e-01, -2.0566e+10,  8.5920e+09, -1.8682e+00],\n",
              "        [ 4.9920e-01, -6.4764e-01,  1.1434e+00, -6.5813e-01,  6.3866e-02],\n",
              "        [-2.6595e-01, -1.7638e-01, -4.6601e-01,  1.2395e+00, -4.0541e-04]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QL3zuTcrKWCZ",
        "outputId": "126c3f3a-6e5f-4dbb-e49a-7a8d884ebacb"
      },
      "source": [
        "# in-place addition\n",
        "x = torch.zeros(3, 5)\n",
        "x.add_(y)\n",
        "x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.4295,  0.9393,  1.2178,  0.6311, -1.8682],\n",
              "        [ 0.4992, -0.6476,  1.1434, -0.6581,  0.0639],\n",
              "        [-0.2660, -0.1764, -0.4660,  1.2395, -0.0004]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9RVjVl7KWCZ",
        "outputId": "ddef8e73-d4ec-47e2-978a-6a1bb7fff91b"
      },
      "source": [
        "# subtract\n",
        "torch.sub(x, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J08azidqKWCa",
        "outputId": "f6c64b92-d5e3-40eb-bbc1-c6a6bd4a3f09"
      },
      "source": [
        "# multiply\n",
        "torch.mul(x, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2.0436e+00, 8.8229e-01, 1.4831e+00, 3.9826e-01, 3.4902e+00],\n",
              "        [2.4920e-01, 4.1944e-01, 1.3073e+00, 4.3313e-01, 4.0788e-03],\n",
              "        [7.0731e-02, 3.1111e-02, 2.1717e-01, 1.5363e+00, 1.6436e-07]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71bv6JMAKWCa",
        "outputId": "d4e5fa5c-76dd-483b-90c9-5a971065f8d3"
      },
      "source": [
        "# division\n",
        "torch.div(x, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dShtxU0dKWCa",
        "outputId": "e1701b61-d923-4729-933c-7acfbced765f"
      },
      "source": [
        "# out parameter\n",
        "zero = torch.zeros(3, 5)\n",
        "one = torch.ones(3, 5)\n",
        "result = torch.empty(3, 5)\n",
        "torch.add(zero, one, out=result)\n",
        "result"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LePf0Cf8KWCa"
      },
      "source": [
        "## Resizing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYnWyK71KWCa",
        "outputId": "c981572b-8668-45a9-9e95-a2340a1e6dc4"
      },
      "source": [
        "# use torch.view\n",
        "x = torch.ones(3, 5)\n",
        "print(x.size())\n",
        "x = x.view(5, 3)\n",
        "print(x.size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 5])\n",
            "torch.Size([5, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9zZRKSyKWCb"
      },
      "source": [
        "## Interact with Numpy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSwVP3xUKWCb"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ao9ntWNTKWCb",
        "outputId": "32e82113-f79b-4e2d-d4c8-b95d119bec45"
      },
      "source": [
        "np_array = np.random.randn(3, 3)\n",
        "np_array.shape, type(np_array)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((3, 3), numpy.ndarray)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6n5Pv4UDKWCb",
        "outputId": "0bf2a267-2645-4880-f819-55694d8383bf"
      },
      "source": [
        "# torch.from_numpy()\n",
        "torch_array = torch.from_numpy(np_array)\n",
        "torch_array.size(), type(torch_array)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([3, 3]), torch.Tensor)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4f4l4fAKWCb",
        "outputId": "58619799-aac2-4f55-dd69-a3f69b4c7595"
      },
      "source": [
        "# torch.numpy()\n",
        "to_numpy_array = torch_array.numpy()\n",
        "to_numpy_array.shape, type(to_numpy_array)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((3, 3), numpy.ndarray)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jqr1wbgpKWCc"
      },
      "source": [
        "# Data Handling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCe35KwpKWCc"
      },
      "source": [
        "## MNIST Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPMZ3XJUKWCc"
      },
      "source": [
        "### torchvision.datasets.MNIST\n",
        "torchvision.datasets.MNIST(root, train=True, transform=None, target_transform=None, download=False)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5mdCvXTKWCc"
      },
      "source": [
        "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMkC5xOIKWCc",
        "outputId": "6a5c2ceb-100d-42b8-c464-bdf0494c30b6"
      },
      "source": [
        "len(mnist_trainset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQtl3kltKWCc",
        "outputId": "37c01c63-4e01-4d6b-b350-c66c0eba3101"
      },
      "source": [
        "type(mnist_trainset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torchvision.datasets.mnist.MNIST"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPNi0wYFKWCc"
      },
      "source": [
        "BATCH_SIZE = 64"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8H1vWhVKWCc"
      },
      "source": [
        "# torchvision.datasets.MNIST outputs a set of PIL images\n",
        "# We transform them to tensors\n",
        "MNIST_transform = transforms.Compose([\n",
        "    transforms.ToTensor(), # first, convert image to PyTorch tensor\n",
        "    transforms.Normalize((0.1307,), (0.3081,)) # normalize inputs\n",
        "])\n",
        "\n",
        "# Load and transform data\n",
        "trainset = datasets.MNIST('/tmp', train=True, download=True, transform=MNIST_transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = datasets.MNIST('/tmp', train=False, download=True, transform=MNIST_transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hA-ke2DKWCd"
      },
      "source": [
        "# Image(features), Label(labels) loading through iteration\n",
        "img, lbl = next(iter(trainloader))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMLgDdBKKWCd",
        "outputId": "2324dcc0-8e39-428e-aaac-4fde6ca003f6"
      },
      "source": [
        "img.size(), lbl.size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([64, 1, 28, 28]), torch.Size([64]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BRziVXPKWCd"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import torchvision\n",
        "\n",
        "def visualize(image):\n",
        "    im = torchvision.utils.make_grid(image)\n",
        "    plt.imshow(np.transpose(im.numpy(), (1, 2, 0)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKUVCWjIKWCd",
        "outputId": "79521da2-f2d8-4d7c-92e3-003f9c8d0a1e"
      },
      "source": [
        "visualize(img[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdypVJjNKWCd"
      },
      "source": [
        "# Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9NAeXYkKWCd"
      },
      "source": [
        "## Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsqL7oCCKWCd"
      },
      "source": [
        "# hyperparameters here\n",
        "input_size = 28*28\n",
        "hidden_1_size = 128\n",
        "hidden_2_size = 64\n",
        "output_size = 10\n",
        "learning_rate = 0.01\n",
        "training_epoch = 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxBFvJaCKWCd"
      },
      "source": [
        "## Build Network (Model Sequence)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b__RRqfNKWCe"
      },
      "source": [
        "from collections import OrderedDict\n",
        "model_sequence = OrderedDict([\n",
        "    ('fc1', nn.Linear(input_size, hidden_1_size)),\n",
        "    ('relu1', nn.ReLU()),\n",
        "    ('fc2', nn.Linear(hidden_1_size, hidden_2_size)),\n",
        "    ('relu2', nn.ReLU()),\n",
        "    ('output', nn.Linear(hidden_2_size, output_size)),\n",
        "    ('softmax', nn.Softmax(dim=1))\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWdUcKxJKWCe"
      },
      "source": [
        "model = nn.Sequential(model_sequence)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lMzd4UfKWCe",
        "outputId": "e1f022d1-3a79-4f59-f3a4-9c3a16a46bb9"
      },
      "source": [
        "model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
              "  (relu1): ReLU()\n",
              "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (relu2): ReLU()\n",
              "  (output): Linear(in_features=64, out_features=10, bias=True)\n",
              "  (softmax): Softmax()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eu8sx-rnKWCe"
      },
      "source": [
        "## Optimizer and Cost Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3VvO5K3KWCe"
      },
      "source": [
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6z6LnmuKWCe"
      },
      "source": [
        "loss_function = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5JmPiGYKWCe",
        "outputId": "b08705e3-50ae-4dfe-f7a0-12ddfca63536"
      },
      "source": [
        "print_every = 50\n",
        "\n",
        "for epoch in range(training_epoch):\n",
        "    cnt = 0\n",
        "    running_loss = 0\n",
        "    for image, label in iter(trainloader):\n",
        "        cnt += 1\n",
        "        # resize images to 784 from (28, 28) - flatten\n",
        "        image.resize_(image.size()[0], 28*28)\n",
        "        \n",
        "        # zero to all gradients\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # train inputs\n",
        "        output = model(image)\n",
        "\n",
        "        # calculate losses\n",
        "        loss = loss_function(output, label)\n",
        "        loss.backward()\n",
        "        \n",
        "        # apply gradient descent\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "        \n",
        "        if cnt % print_every == 0:\n",
        "            print(\"epoch: {}, loss: {}\".format(epoch, running_loss / print_every))\n",
        "            running_loss = 0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 0, loss: 2.2956738233566285\n",
            "epoch: 0, loss: 2.2634285259246827\n",
            "epoch: 0, loss: 2.126222529411316\n",
            "epoch: 0, loss: 1.9458885240554809\n",
            "epoch: 0, loss: 1.8158244919776916\n",
            "epoch: 0, loss: 1.7266433215141297\n",
            "epoch: 0, loss: 1.6785507035255431\n",
            "epoch: 0, loss: 1.6476908349990844\n",
            "epoch: 0, loss: 1.6150638198852538\n",
            "epoch: 0, loss: 1.595977761745453\n",
            "epoch: 0, loss: 1.5894164228439331\n",
            "epoch: 0, loss: 1.5833081746101378\n",
            "epoch: 0, loss: 1.5858566403388976\n",
            "epoch: 0, loss: 1.5770608925819396\n",
            "epoch: 0, loss: 1.5750331377983093\n",
            "epoch: 0, loss: 1.5662693929672242\n",
            "epoch: 0, loss: 1.5574766206741333\n",
            "epoch: 0, loss: 1.5587181234359742\n",
            "epoch: 1, loss: 1.5572782039642334\n",
            "epoch: 1, loss: 1.5531983757019043\n",
            "epoch: 1, loss: 1.5566648745536804\n",
            "epoch: 1, loss: 1.558462052345276\n",
            "epoch: 1, loss: 1.550595724582672\n",
            "epoch: 1, loss: 1.5468142676353454\n",
            "epoch: 1, loss: 1.548676724433899\n",
            "epoch: 1, loss: 1.5500653338432313\n",
            "epoch: 1, loss: 1.5432995986938476\n",
            "epoch: 1, loss: 1.5403948664665221\n",
            "epoch: 1, loss: 1.5389266109466553\n",
            "epoch: 1, loss: 1.546637682914734\n",
            "epoch: 1, loss: 1.5376596236228943\n",
            "epoch: 1, loss: 1.5417435932159425\n",
            "epoch: 1, loss: 1.528404839038849\n",
            "epoch: 1, loss: 1.5458406853675841\n",
            "epoch: 1, loss: 1.5471224236488341\n",
            "epoch: 1, loss: 1.5434219622612\n",
            "epoch: 2, loss: 1.535258002281189\n",
            "epoch: 2, loss: 1.523565399646759\n",
            "epoch: 2, loss: 1.5361124062538147\n",
            "epoch: 2, loss: 1.5340202403068544\n",
            "epoch: 2, loss: 1.5335375380516052\n",
            "epoch: 2, loss: 1.5270027947425842\n",
            "epoch: 2, loss: 1.5271691632270814\n",
            "epoch: 2, loss: 1.5195678615570067\n",
            "epoch: 2, loss: 1.5260499787330628\n",
            "epoch: 2, loss: 1.527957887649536\n",
            "epoch: 2, loss: 1.523062562942505\n",
            "epoch: 2, loss: 1.528022162914276\n",
            "epoch: 2, loss: 1.520134825706482\n",
            "epoch: 2, loss: 1.5208773827552795\n",
            "epoch: 2, loss: 1.5267586779594422\n",
            "epoch: 2, loss: 1.5265515041351319\n",
            "epoch: 2, loss: 1.5250012922286986\n",
            "epoch: 2, loss: 1.5276229429244994\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvxJpDGCKWCe",
        "outputId": "3f141f26-64f2-4b03-ac0c-d3cf7ecf916a"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        images.resize_(images.size()[0], 28*28)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 94 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIVHeQyXKWCf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}